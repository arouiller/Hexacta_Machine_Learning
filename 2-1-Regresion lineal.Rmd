---
title: "Regresion lineal"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Regresión lineal

```{r}
rm(list=ls())
```

### Generación de datos aleatorios
```{r}
x <- runif(1000, -5, 5)
y <- x + rnorm(1000) + 3
plot(x,y, col=rgb(0.2,0.4,0.6,0.4), main='Regresión lineal con descenso de gradiente')
```

### Modelo lineal
Modelo lineal y representacion
```{r}
res <- lm( y ~ x )

m <- round(as.numeric(res$coefficients['(Intercept)']), 3)
b <- round(as.numeric(res$coefficients['x']), 3)

c(m, b)

titulo = paste('Regresion lineal (y=',m,'+',b," * x)", sep='')

plot(x,y, col=rgb(0.2,0.4,0.6,0.4), main= titulo) + abline(res, col='blue')
```



### Implementacion
```{r}
# función de error
cost <- function(X, y, theta) {
  sum( (X %*% theta - y)^2 ) / (2*length(y))
}

## Parámetros
    # Tasa de crecimiento
    alpha <- 0.04
    
    # Número máximo de iteraciones
    num_iters <- 250

# Guardamos la historia de los costos y los coefinicientes
cost_history <- double(num_iters)
theta_history <- list(num_iters)

# Coeficientes iniciales aleatorios
theta <- matrix(c(runif(1, -5, 5), runif(1, -5, 5)), nrow=2)

# add a column of 1's for the intercept coefficient
X <- cbind(1, matrix(x))

i <-1
# Descenso del gradiente
while(i <= num_iters ){
  #Error en lo predicho vs lo real
  error <- (X %*% theta - y)
  
  delta <- t(X) %*% error / length(y)
  #Nuevos parametros
  theta <- theta - alpha * delta
  
  #Almacenamos el costo
  cost_history[i] <- cost(X, y, theta)
  #Almacenamos los parametros
  theta_history[[i]] <- theta
  i <- i+1
}

m <- round(theta[1,1], 3)
b <- round(theta[2,1], 3)

titulo = paste('Linear regression by gradient descent (y=',m,'+',b," * x)", sep='')

plot(x,y, col=rgb(0.2,0.4,0.6,0.4), main=titulo)
for (i in 1:num_iters) {
  color = ifelse(i==1, 'green', 'red')
  abline(coef=theta_history[[i]], col=color)
}
abline(coef=theta, col='blue')
```

